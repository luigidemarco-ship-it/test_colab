{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Colab-ready notebook\n",
                "\n",
                "This notebook is minimal and ready to run in Google Colab."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a13ca46e",
            "metadata": {},
            "outputs": [
                {
                    "ename": "LoadError",
                    "evalue": "UndefVarError: `nvidia` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
                    "output_type": "error",
                    "traceback": [
                        "UndefVarError: `nvidia` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
                        "",
                        "Stacktrace:",
                        " [1] top-level scope",
                        "\u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[4]:1\u001b[24m\u001b[39m"
                    ]
                }
            ],
            "source": [
                "# Verifica che la GPU sia attiva\n",
                "import torch\n",
                "print(\"Torch CUDA available:\", torch.cuda.is_available())\n",
                "print(\"Device name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"N/A\")\n",
                "\n",
                "# Un semplice test: moltiplicazione matriciale grande su GPU\n",
                "if torch.cuda.is_available():\n",
                "    device = torch.device(\"cuda\")\n",
                "else:\n",
                "    device = torch.device(\"cpu\")\n",
                "\n",
                "# crea due matrici grandi\n",
                "a = torch.randn((5000,5000), device=device)\n",
                "b = torch.randn((5000,5000), device=device)\n",
                "\n",
                "# moltiplica\n",
                "import time\n",
                "start = time.time()\n",
                "c = torch.matmul(a, b)\n",
                "end = time.time()\n",
                "\n",
                "print(f\"Time taken on {device}: {end-start:.3f} seconds\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {
                "id": "init"
            },
            "outputs": [
                {
                    "ename": "LoadError",
                    "evalue": "ArgumentError: Package sys not found in current path.\n- Run `import Pkg; Pkg.add(\"sys\")` to install the sys package.",
                    "output_type": "error",
                    "traceback": [
                        "ArgumentError: Package sys not found in current path.\n- Run `import Pkg; Pkg.add(\"sys\")` to install the sys package.",
                        "",
                        "Stacktrace:",
                        " [1] \u001b[0m\u001b[1mmacro expansion\u001b[22m",
                        "\u001b[90m   @\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mloading.jl:2296\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m",
                        " [2] \u001b[0m\u001b[1mmacro expansion\u001b[22m",
                        "\u001b[90m   @\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mlock.jl:273\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m",
                        " [3] \u001b[0m\u001b[1m__require\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90minto\u001b[39m::\u001b[0mModule, \u001b[90mmod\u001b[39m::\u001b[0mSymbol\u001b[0m\u001b[1m)\u001b[22m",
                        "\u001b[90m   @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mloading.jl:2271\u001b[24m\u001b[39m",
                        " [4] \u001b[0m\u001b[1m#invoke_in_world#3\u001b[22m",
                        "\u001b[90m   @\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4messentials.jl:1089\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m",
                        " [5] \u001b[0m\u001b[1minvoke_in_world\u001b[22m",
                        "\u001b[90m   @\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4messentials.jl:1086\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m",
                        " [6] \u001b[0m\u001b[1mrequire\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90minto\u001b[39m::\u001b[0mModule, \u001b[90mmod\u001b[39m::\u001b[0mSymbol\u001b[0m\u001b[1m)\u001b[22m",
                        "\u001b[90m   @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mloading.jl:2260\u001b[24m\u001b[39m"
                    ]
                }
            ],
            "source": [
                "# Run this cell to verify the Python environment\n",
                "import sys\n",
                "print('Python', sys.version)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "955dd69d",
            "metadata": {},
            "outputs": [
                {
                    "ename": "LoadError",
                    "evalue": "ArgumentError: Package torch not found in current path.\n- Run `import Pkg; Pkg.add(\"torch\")` to install the torch package.",
                    "output_type": "error",
                    "traceback": [
                        "ArgumentError: Package torch not found in current path.\n- Run `import Pkg; Pkg.add(\"torch\")` to install the torch package.",
                        "",
                        "Stacktrace:",
                        " [1] \u001b[0m\u001b[1mmacro expansion\u001b[22m",
                        "\u001b[90m   @\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mloading.jl:2296\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m",
                        " [2] \u001b[0m\u001b[1mmacro expansion\u001b[22m",
                        "\u001b[90m   @\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mlock.jl:273\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m",
                        " [3] \u001b[0m\u001b[1m__require\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90minto\u001b[39m::\u001b[0mModule, \u001b[90mmod\u001b[39m::\u001b[0mSymbol\u001b[0m\u001b[1m)\u001b[22m",
                        "\u001b[90m   @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mloading.jl:2271\u001b[24m\u001b[39m",
                        " [4] \u001b[0m\u001b[1m#invoke_in_world#3\u001b[22m",
                        "\u001b[90m   @\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4messentials.jl:1089\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m",
                        " [5] \u001b[0m\u001b[1minvoke_in_world\u001b[22m",
                        "\u001b[90m   @\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4messentials.jl:1086\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m",
                        " [6] \u001b[0m\u001b[1mrequire\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90minto\u001b[39m::\u001b[0mModule, \u001b[90mmod\u001b[39m::\u001b[0mSymbol\u001b[0m\u001b[1m)\u001b[22m",
                        "\u001b[90m   @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mloading.jl:2260\u001b[24m\u001b[39m"
                    ]
                }
            ],
            "source": [
                "import torch\n",
                "if torch.cuda.is_available():\n",
                "    print(\"CUDA GPU:\", torch.cuda.get_device_name(0))\n",
                "else:\n",
                "    print(\"No CUDA GPU available (torch.cuda.is_available() is False)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "be483a3e",
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "colab": {
            "collapsed_sections": [],
            "name": "test.ipynb",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "julia 1.11",
            "language": "julia",
            "name": "julia"
        },
        "language_info": {
            "file_extension": ".jl",
            "mimetype": "application/julia",
            "name": "julia",
            "version": "1.11.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
